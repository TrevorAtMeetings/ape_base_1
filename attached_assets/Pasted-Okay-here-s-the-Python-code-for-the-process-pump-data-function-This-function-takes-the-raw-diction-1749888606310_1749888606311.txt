Okay, here's the Python code for the process_pump_data function. This function takes the raw dictionary (output by parse_scg_to_raw_dict which you'd have in the same Python file) and processes it into a structured format, including calculating power.

def process_pump_data(raw_data):
    """
    Processes a raw dictionary of pump data (from SCG file) into a structured
    format with proper data types and calculated power.

    Args:
        raw_data (dict): A flat dictionary with string values, as output by
                         parse_scg_to_raw_dict.

    Returns:
        dict: A structured dictionary containing 'pump_info' and a list of 'curves'.
              Returns None if essential data (like raw_data) is missing.
    """
    if not raw_data:
        print("Error: No raw_data provided to process_pump_data.")
        return None

    structured_data = {
        "pump_info": {},
        "curves": []
    }

    # --- Helper functions for safe type conversion ---
    def to_float(value, default=0.0):
        try:
            return float(str(value).strip())
        except (ValueError, TypeError):
            return default

    def to_int(value, default=0):
        try:
            return int(float(str(value).strip())) # float() handles "1.0" for int conversion
        except (ValueError, TypeError):
            return default

    def to_bool(value, default=False):
        if isinstance(value, str):
            return value.strip().lower() == 'true'
        return default

    # --- 1. Populate pump_info (Scalar Data) ---
    pi = structured_data["pump_info"] # Alias for pump_info dictionary

    pi['pPumpCode'] = raw_data.get('pPumpCode', '')
    pi['pSuppName'] = raw_data.get('pSuppName', '')
    pi['pKWMax'] = to_float(raw_data.get('pKWMax'))
    pi['pBEPFlowStd'] = to_float(raw_data.get('pBEPFlowStd'))
    pi['pBEPHeadStd'] = to_float(raw_data.get('pBEPHeadStd'))
    pi['pNPSHEOC'] = to_float(raw_data.get('pNPSHEOC'))

    for i in range(1, 9): # pFilter1 to pFilter8
        pi[f'pFilter{i}'] = raw_data.get(f'pFilter{i}', '')

    pi['pVarN'] = to_bool(raw_data.get('pVarN'))
    pi['pVarD'] = to_bool(raw_data.get('pVarD'))
    pi['pImpImperial'] = to_bool(raw_data.get('pImpImperial'))
    pi['pMotorImperial'] = to_bool(raw_data.get('pMotorImperial'))

    pi['pUnitFlow'] = raw_data.get('pUnitFlow', 'm^3/hr') # Default if missing
    pi['pUnitHead'] = raw_data.get('pUnitHead', 'm')     # Default if missing

    pi['pMaxQ'] = to_float(raw_data.get('pMaxQ'))
    pi['pMaxH'] = to_float(raw_data.get('pMaxH'))
    pi['pMinImpD'] = to_float(raw_data.get('pMinImpD'))
    pi['pMaxImpD'] = to_float(raw_data.get('pMaxImpD'))
    pi['pMinSpeed'] = to_float(raw_data.get('pMinSpeed'))
    pi['pMaxSpeed'] = to_float(raw_data.get('pMaxSpeed'))
    pi['pPumpTestSpeed'] = to_float(raw_data.get('pPumpTestSpeed'))
    pi['pPumpImpDiam'] = to_float(raw_data.get('pPumpImpDiam'))
    pi['nPolyOrder'] = to_int(raw_data.get('nPolyOrder'))
    pi['pM_NAME'] = raw_data.get('pM_NAME', '') # Could be "CODE;SHORTCODE" or just "CODE"

    # TASGRX fields
    for param in ["Flow", "Head", "Eff", "Power", "NPSH"]:
        for i in range(4): # 0 to 3
            pi[f'pTASGRX_{param}{i}'] = to_float(raw_data.get(f'pTASGRX_{param}{i}'))

    # Process pM_Diam, pM_Speed, pM_EffIso
    def parse_space_separated_floats(key_name):
        val_str = raw_data.get(key_name, '')
        return [to_float(v) for v in val_str.split(' ') if v.strip() and to_float(v, None) is not None and to_float(v) != 0.0]

    pi['diameters_available'] = parse_space_separated_floats('pM_Diam')
    pi['speeds_available'] = parse_space_separated_floats('pM_Speed')
    pi['iso_efficiency_lines'] = parse_space_separated_floats('pM_EffIso')

    # --- 2. Determine Number of Curves ---
    num_curves = to_int(raw_data.get('pHeadCurvesNo', '0'))
    if num_curves == 0:
        # No curves to process, but pump_info might still be relevant
        # Or you could log a warning/error
        print(f"Warning: pHeadCurvesNo is 0 or missing for {pi.get('pPumpCode')}. No curves will be processed.")
        return structured_data # Return with empty curves list

    # --- 3. Parse Curve Identifiers (pM_IMP) ---
    curve_identifiers = []
    imp_str_raw = raw_data.get('pM_IMP', '')
    for i in range(num_curves):
        start_index = i * 8
        end_index = start_index + 8
        if end_index <= len(imp_str_raw):
            identifier_padded = imp_str_raw[start_index:end_index]
            curve_identifiers.append(identifier_padded.strip())
        else:
            curve_identifiers.append(f"Unknown_ID_{i+1}") # Fallback

    # --- 4. Parse Curve Data Arrays (pM_FLOW, pM_HEAD, pM_EFF, pM_NP) ---
    # Helper to split curve data strings
    def get_curve_series_data(key_name, num_expected_curves):
        data_str_raw = raw_data.get(key_name, '')
        series_str_list = data_str_raw.split('|')
        # If only one curve, split won't add more elements if no '|'
        if len(series_str_list) == 1 and num_expected_curves > 1 and '|' not in data_str_raw:
             # This might indicate an issue if more curves were expected but data is for one
             pass # Or handle error
        elif len(series_str_list) != num_expected_curves and data_str_raw:
            print(f"Warning: Mismatch in {key_name}. Expected {num_expected_curves} curve sets, found {len(series_str_list)}.")
            # Pad with empty strings if fewer than expected, or truncate if more
            series_str_list.extend([""] * (num_expected_curves - len(series_str_list)))
            series_str_list = series_str_list[:num_expected_curves]
        return series_str_list

    all_curves_flow_str  = get_curve_series_data('pM_FLOW', num_curves)
    all_curves_head_str  = get_curve_series_data('pM_HEAD', num_curves)
    all_curves_eff_str   = get_curve_series_data('pM_EFF', num_curves)
    all_curves_npsh_str  = get_curve_series_data('pM_NP', num_curves)


    # --- 5. Construct Each Curve Object and Calculate Power ---
    for i in range(num_curves):
        current_curve_obj = {
            "identifier": curve_identifiers[i] if i < len(curve_identifiers) else f"Curve_{i+1}",
            "flow": [], "head": [], "efficiency": [], "npsh": [], "power_calculated": []
        }

        # Convert point strings to lists of floats
        current_curve_obj['flow']       = [to_float(p.strip()) for p in all_curves_flow_str[i].split(';') if p.strip()]
        current_curve_obj['head']       = [to_float(p.strip()) for p in all_curves_head_str[i].split(';') if p.strip()]
        current_curve_obj['efficiency'] = [to_float(p.strip()) for p in all_curves_eff_str[i].split(';') if p.strip()]
        current_curve_obj['npsh']       = [to_float(p.strip()) for p in all_curves_npsh_str[i].split(';') if p.strip()]

        # --- Calculate Power ---
        # Unit conversion factors (matching VBA logic)
        unit_flow = pi.get('pUnitFlow', 'm^3/hr')
        unit_head = pi.get('pUnitHead', 'm')

        con_flow = 1.0 / 3600.0  # Default for m^3/hr to m^3/s
        if unit_flow == "l/sec":
            con_flow = 1.0 / 1000.0
        elif unit_flow == "US gpm":
            con_flow = 1.0 / 15850.32 # US GPM to m^3/s (VBA used 15850)

        con_head = 1.0  # Default for m
        if unit_head == "bar":
            con_head = 10.19716 # m water column per bar
        elif unit_head == "kPa":
            # Standard conversion: 1 kPa = 0.1019716 m H2O.
            # VBA used 0.305, which is closer to ft H2O from psi if kPa was misinterp.
            # Using standard conversion for m H2O. If results differ significantly from Excel,
            # the 0.305 constant might have a specific non-standard basis.
            con_head = 0.1019716
        elif unit_head == "ft":
            con_head = 0.3048 # m per ft

        # Assuming g = 9.81 m/s^2 and rho_water = 1000 kg/m^3 (implicit in VBA's 9.81 factor for kW)
        num_points = len(current_curve_obj['flow'])
        # Ensure all data lists have same length for power calculation
        min_len = min(len(current_curve_obj['flow']), len(current_curve_obj['head']), len(current_curve_obj['efficiency']))

        for j in range(min_len):
            q_val = current_curve_obj['flow'][j]
            h_val = current_curve_obj['head'][j]
            eff_val = current_curve_obj['efficiency'][j] # This is in percent (e.g., 70 for 70%)

            if eff_val > 0:
                # Power (kW) = (Q_m3/s * H_m * rho_kg/m3 * g_m/s2) / (eff_decimal * 1000)
                # VBA: Round(flowVal * conFlow * headVal * conHead * 9.81 * 100 / effVal, 2)
                # This is equivalent to (Q_converted * H_converted * 9.81) / (eff_percentage / 100.0)
                power_kw = (q_val * con_flow * h_val * con_head * 9.81) / (eff_val / 100.0)
                current_curve_obj['power_calculated'].append(round(power_kw, 2))
            else:
                current_curve_obj['power_calculated'].append(0.0)
        
        # If lists were unequal, pad power with 0 for remaining points
        if len(current_curve_obj['power_calculated']) < num_points:
            current_curve_obj['power_calculated'].extend([0.0] * (num_points - len(current_curve_obj['power_calculated'])))


        structured_data["curves"].append(current_curve_obj)

    return structured_data

# --- Example Usage (assuming parse_scg_to_raw_dict is defined elsewhere) ---
# if __name__ == '__main__':
#     # You would need the parse_scg_to_raw_dict function from the previous step
#     # For demonstration, let's assume raw_pump_data is populated:
#     # raw_pump_data = parse_scg_to_raw_dict("path_to_your_file.scg")
#
#     # Dummy raw_data for testing process_pump_data directly
#     raw_pump_data_example = {
#         "pPumpCode": "10 WO 4P", "pSuppName": "APE PUMPS", "pKWMax": "0",
#         "pBEPFlowStd": "133.4", "pBEPHeadStd": "6.62", "pNPSHEOC": "0",
#         "pFilter1": "APE PUMPS", "pFilter2": "WATER SUPPLY", "pFilter3": "VERTICAL TURBINE",
#         "pFilter4": "VTP", "pFilter5": "1460", "pFilter6": "BS", "pFilter7": "OPEN", "pFilter8": "APE PUMPS",
#         "pHeadCurvesNo": "1", "pEffCurvesNo": "1", "pNPSHCurvesNo": "1",
#         "pVarN": "True", "pVarD": "True", "pImpImperial": "False", "pMotorImperial": "False",
#         "pUnitFlow": "m^3/hr", "pUnitHead": "m",
#         "pMaxQ": "200.3", "pMaxH": "10.75", # Max values from the single curve
#         "pMinImpD": "160", "pMaxImpD": "197", "pMinSpeed": "900", "pMaxSpeed": "1460",
#         "pPumpTestSpeed": "1450", "pPumpImpDiam": "0", "nPolyOrder": "3",
#         "pM_Diam": "     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0",
#         "pM_Speed": "     900    1100    1300    1500    1700    1900       0       0",
#         "pM_EffIso": " 40.0 50.0 55.0 60.0 64.0 67.0  0.0  0.0",
#         "pM_FLOW": "25;32;63.3;101.1;132.4;175.6;200.3",
#         "pM_HEAD": "10.75;10.5;9.5;8.1;6.6;4.5;3",
#         "pM_EFF": "27;30;52;65;69;63;52",
#         "pM_NP": "0;0;0;0;0;0;0", # NPSH data is all zeros
#         "pM_NAME": "10 WO 4P",
#         "pM_IMP": "  197.00"
#         # TASGRX fields would be here, all "0"
#     }
#     for param in ["Flow", "Head", "Eff", "Power", "NPSH"]:
#         for i in range(4): raw_pump_data_example[f'pTASGRX_{param}{i}'] = "0"

#     if raw_pump_data_example:
#         processed_data = process_pump_data(raw_pump_data_example)
#         if processed_data:
#             import json
#             print(json.dumps(processed_data, indent=4))

#             # Example: Print flow and calculated power for the first curve
#             if processed_data["curves"]:
#                 first_curve = processed_data["curves"][0]
#                 print(f"\nPump: {processed_data['pump_info']['pPumpCode']}")
#                 print(f"Curve ID: {first_curve['identifier']}")
#                 print(f"Flow ({processed_data['pump_info']['pUnitFlow']}): {first_curve['flow']}")
#                 print(f"Head ({processed_data['pump_info']['pUnitHead']}): {first_curve['head']}")
#                 print(f"Efficiency (%): {first_curve['efficiency']}")
#                 print(f"NPSH ({processed_data['pump_info']['pUnitHead']}): {first_curve['npsh']}")
#                 print(f"Calculated Power (kW): {first_curve['power_calculated']}")


Key Points and Explanations in the Code:

Helper Functions (to_float, to_int, to_bool): These make conversions from string values in raw_data safer and cleaner.

pump_info Population: Iterates through known scalar keys, gets them from raw_data (with defaults if missing), and converts them.

pM_Diam, pM_Speed, pM_EffIso Parsing: The parse_space_separated_floats helper splits these strings by space, converts to float, and filters out zeros and non-convertible parts.

Number of Curves: Reads pHeadCurvesNo to determine how many curve datasets to expect.

Curve Identifiers (pM_IMP): Extracts 8-character segments and strips whitespace.

Curve Data Arrays (pM_FLOW, etc.):

get_curve_series_data splits the main string by | to get data for each curve.

It includes a basic check for mismatched number of curve sets.

Then, for each curve, it splits the semicolon-separated points into lists of floats.

Power Calculation:

Retrieves pUnitFlow and pUnitHead to select conversion factors.

Unit Conversion Factors: I've used standard factors.

US gpm to m^3/s: 1 / 15850.32 (close to VBA's 1/15850).

kPa to m head: 0.1019716. This is a point of potential difference from your Excel sheet if it uses the 0.305 factor from the VBA ImportJsonToExcel code you showed earlier. The 0.305 might have a specific basis (e.g., ft H2O from kPa, or a non-standard fluid). The code uses the standard m H2O conversion.

The formula used: power_kw = (q_val * con_flow * h_val * con_head * 9.81) / (eff_val / 100.0) directly matches the intent of the VBA formula Round(flowVal * conFlow * headVal * conHead * 9.81 * 100 / effVal, 2), assuming eff_val is in percent.

Error Handling/Robustness:

Uses .get() for dictionary access to avoid KeyError.

Basic checks for number of curves and consistency.

Ensures power calculation loop doesn't go out of bounds if flow/head/eff lists have different lengths for some reason by using min_len.

This function, combined with the parse_scg_to_raw_dict function, should give you a robust way to read your .scg files and get the data into a usable Python structure. Remember to test it with various .scg files to catch any edge cases specific to your data. The most likely area for fine-tuning will be the unit conversion factors if your Excel sheet has specific, non-standard assumptions embedded in its calculations.